FROM THIS POINT NO BIAS EXPERIMENT IS USING SPIEGEL
NOTE: for all of below (if on cluster) run first one first
+ means no dependency on former?

order that I've done these:
1. rel_avg
2. bias_avg
3. bias_sel
4. seq_bias_embed
5. bias_embed
6. seq_bias_sel
7. rel_sentic
8. bias_sentic
9. bias_avg_arch
10. seq_rel_embed

======================================
To establish avg_std better than avg
"bias_avg"

bias_svm_w2v_avg (160)
bias_svm_w2v_avg_std (370)
bias_w2v_avg (0)
bias_w2v_avg_std (10)

compile_results.py -e run_0/bias_svm_w2v_avg,run_0/bias_svm_w2v_avg_std,run_0/bias_w2v_avg,run_0/bias_w2v_avg_std -o bias_avg_0

compile_results.py -e run_1/bias_svm_w2v_avg,run_1/bias_svm_w2v_avg_std,run_1/bias_w2v_avg,run_1/bias_w2v_avg_std -o bias_avg_1

Times run: 2

Conclusions:
* SVM seems to do better than NN
* std_dev did slightly better for NN, not for SVM

======================================
To establish better selection set:
"bias_sel"

bias_svm_w2v_avg (160)
bias_svm_w2v_avg_allsides_all (380)
bias_svm_w2v_avg_mbm (390)
bias_svm_w2v_avg_below20flip (400)
bias_svm_w2v_avg_below25flip (410)

compile_results.py -e run_0/bias_svm_w2v_avg,run_0/bias_svm_w2v_avg_allsides_all,run_0/bias_svm_w2v_avg_mbm,run_0/bias_svm_w2v_avg_below20flip,run_0/bias_svm_w2v_avg_below25flip -o bias_sel_0

Times run: 1

Conclusions:
* Collective labelling did better than allsides, slightly worse than MBM (on AL, collective actually did better than both
* Flipped labels on collective did do better than mbm

======================================
To establish better selection set:
"rel_sel"

rel_svm_w2v_avg (350)
rel_svm_w2v_avg_ng (700)
rel_svm_w2v_avg_mbfc (710)


compile_results.py -e run_0/rel_svm_w2v_avg,run_0/rel_svm_w2v_avg_ng,run_0/rel_svm_w2v_avg_mbfc -o rel_sel_0

Times run: 1

Conclusions:
* Compiled is better on source, _barely_ better than MBFC on AL, and slightly worse on AL unseen, definitely **run this again**


======================================
To establish better selection set with sequence data:
"seq_bias_sel"

bias_w2v_seq (60)
bias_w2v_seq_allsides_all (440)
bias_w2v_seq_mbm (450)
bias_w2v_seq_below20flip (460)
bias_w2v_seq_below25flip (470)

Times run: 1

compile_results.py -e seq/bias_w2v_seq,seq/bias_w2v_seq_allsides_all,seq/bias_w2v_seq_mbm,seq/bias_w2v_seq_below20flip,seq/bias_w2v_seq_below25flip -o selection_seqs

Conclusions:
* similar to bias_sel, collective better on source than all others, MBM better on AL, but the flip25 did best everywhere

======================================
To establish superior embedding:
"bias_embed"

bias_svm_tfidf (140)
bias_svm_w2v_avg (350)
bias_svm_glove_avg (420)
bias_svm_ft_avg (430)
# bias_tfidf
# bias_w2v_avg
# bias_glove_avg
# bias_ft_avg

compile_results.py -e run_0/bias_svm_tfidf,run_0/bias_svm_w2v_avg,run_0/bias_svm_glove_avg,run_0/bias_svm_ft_avg -o bias_embed_0

Times run: 1

Conclusions:
* W2V worse on source-level tests, but much better generalization to AL
* TFIDF worst on source-level

======================================
To establish superior embedding for sequences:
"seq_bias_embed"

bias_w2v_seq (60)
bias_glove_seq (70)
bias_ft_seq (80)

compile_results.py -e seq/bias_w2v_seq,seq/bias_glove_seq,seq/bias_ft_seq -o seq_bias_embed

Times run: 1

Conclusions:
* W2V better in all instances

======================================
To establish superior embedding for sequences with reliability:
"seq_rel_embed"

rel_w2v_seq (670)
rel_glove_seq (680)
rel_ft_seq (690)

compile_results.py -e seq/rel_w2v_seq,seq/rel_glove_seq,seq/rel_ft_seq -o seq_rel_embed

Times run: 1

Conclusions:
* Glove did better on source-level, and did marginally better on AL, but only by a small amount (they were all very close)

======================================
To establish avg_std better than avg
"rel_avg"

rel_svm_w2v_avg (350)
rel_svm_w2v_avg_std (360)
rel_w2v_avg (300)
rel_w2v_avg_std (310)

compile_results.py -e run_0/rel_svm_w2v_avg,run_0/rel_svm_w2v_avg_std,run_0/rel_w2v_avg,run_0/rel_w2v_avg_std -o rel_avg_0

compile_results.py -e run_1/rel_svm_w2v_avg,run_1/rel_svm_w2v_avg_std,run_1/rel_w2v_avg,run_1/rel_w2v_avg_std -o rel_avg_1

Times run: 2

Conclusions:
* avg appears to outperform avg_std by a small amount in all AL cases
* SVM outperforms NN

======================================
To establish sentics with reliability:
"rel_sentic"

rel_svm_w2v_avg (350) [run]
rel_svm_w2v_limit_avg (480)
rel_svm_w2v_sentic_avg (490)
rel_svm_w2v_sentic_full_avg (500)
rel_svm_w2v_sentic_avg_std (510)
rel_svm_w2v_sentic_full_avg_std (520)

compile_results.py -e run_0/rel_svm_w2v_avg,run_0/rel_svm_w2v_limit_avg,run_0/rel_svm_w2v_sentic_avg,run_0/rel_svm_w2v_sentic_full_avg,run_0/rel_svm_w2v_sentic_avg_std,run_0/rel_svm_w2v_sentic_full_avg_std, -o rel_sentic_0

Times run: 1

Conclusions:
* sentic_full_avg did a _tiny bit_ better than avg on AL, all others (including with avg_std) did worse than regular


======================================
To establish sentics with bias:
"bias_sentic"

bias_svm_w2v_avg (370) [run]
bias_svm_w2v_limit_avg (530)
bias_svm_w2v_sentic_avg (540)
bias_svm_w2v_sentic_full_avg (550)
bias_svm_w2v_sentic_avg_std (560)
bias_svm_w2v_sentic_full_avg_std (570)

compile_results.py -e run_0/bias_svm_w2v_avg,run_0/bias_svm_w2v_limit_avg,run_0/bias_svm_w2v_sentic_avg,run_0/bias_svm_w2v_sentic_full_avg,run_0/bias_svm_w2v_sentic_avg_std,run_0/bias_svm_w2v_sentic_full_avg_std -o bias_sentic_0

Times run: 1

Conclusions:
* Plain does better than all sentic runs for AL





======================================
To establish seq versus avg

TODO (which embedding? [w2v])



======================================
Architecture search for avg bias
"bias_avg_arch"
NOTE: these are all run on below25flip selection set

bias_w2v_avg_arch1 (64, 1) [1] (580)
bias_w2v_avg_arch2 (128, 1) [1] (590)
bias_w2v_avg_arch3 (256, 1) [1] (600)
bias_w2v_avg_arch4 (128, 64, 1) [2] (610)
bias_w2v_avg_arch5 (256, 128, 1) [2] (620)
bias_w2v_avg_arch6 (256, 256, 1) [2] (630)
bias_w2v_avg_arch7 (256, 128, 64, 1) [3] (640)
bias_w2v_avg_arch8 (256, 256, 256, 1) [3] (650)

compile_results.py -e run_0/bias_w2v_avg_arch1,run_0/bias_w2v_avg_arch2,run_0/bias_w2v_avg_arch3,run_0/bias_w2v_avg_arch4,run_0/bias_w2v_avg_arch5,run_0/bias_w2v_avg_arch6,run_0/bias_w2v_avg_arch7,run_0/bias_w2v_avg_arch8 -o bias_avg_arch_0

Times run: 1

Conclusions:
* Surprisingly little variance, everything within 2%
* Arch 4 generally did very slightly better than arch 2 [the latter of which is what I've been using for most]
* Top 3 in order: 4, 2, 5, 

======================================
Architecture search for seq bias
"bias_seq_arch"
NOTE: these are all run on below25flip selection set

bias_w2v_seq_arch1 (128, 1) [1] (720)
bias_w2v_seq_arch2 (256, 1) [1] (730)
bias_w2v_seq_arch3 (128, 128, 1) [2] (740)
bias_w2v_seq_arch4 (128, 128, 128, 1) [4] (750)
bias_w2v_seq_arch5 (256, 128, 64, 1) [4] (760)

-------------------------------
Standalone experiments:

does sentic work better on below25flip and with larger arch?
bias_w2v_sentic_full_avg_std_arch4 (660)


compile_results.py -e run_0/bias_w2v_avg_arch4,run_0/bias_w2v_sentic_full_avg_std_arch4,run_0/bias_svm_w2v_avg,run_0/bias_svm_w2v_sentic_full_avg_std -o senticandflipandarch

Times run: 1

Conclusions:
* Nope, sentics still worse




TODO: rel_embed
