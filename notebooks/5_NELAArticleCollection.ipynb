{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NELA Article Collection\n",
    "\n",
    "Created: 2019.10.8  \n",
    "Notebook sequence: 5\n",
    "\n",
    "For getting code together to build the sets of articles to use for each indicator set\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_balanced_sample(source_name_array, count, reject_minimum=100, force_balance=True, random_seed=13, verbose=True):\n",
    "    building_df = None\n",
    "    counts = {}\n",
    "    minimum_count = 100000000 # derp\n",
    "    returned_counts = {}\n",
    "    rejected = []\n",
    "    \n",
    "    for name in tqdm(source_name_array, \"Querying sources\", disable=(not verbose)):\n",
    "        local_df = util.nela_load_articles_from_source(name)\n",
    "        local_count = local_df.shape[0]\n",
    "        if verbose: print(name, local_count, \"articles\")\n",
    "        \n",
    "        if local_count < reject_minimum:\n",
    "            rejected.append(name)\n",
    "            if verbose: print(name, \"rejected\")\n",
    "            continue\n",
    "    \n",
    "        if local_count < minimum_count:\n",
    "            minimum_count = local_count\n",
    "    \n",
    "        counts[name] = local_count\n",
    "        building_df = util.stack_dfs(building_df, local_df)\n",
    "        \n",
    "    max_possible_balanced = minimum_count*len(counts.keys())\n",
    "    if verbose: print(max_possible_balanced,\"maximum possible balanced sample size\")\n",
    "        \n",
    "    sample_df = None\n",
    "    if count > max_possible_balanced:\n",
    "        if verbose: print(\"Grabbing maximum\")\n",
    "        if force_balance:\n",
    "            if verbose: print(\"Force balance requested, will not return\", count, \"as requested\")\n",
    "            \n",
    "            for name in tqdm(counts.keys(), \"Sampling\", disable=(not verbose)):\n",
    "                source_sample_df = building_df[building_df.source == name].sample(minimum_count, random_state=random_seed)\n",
    "                sample_df = util.stack_dfs(sample_df, source_sample_df)\n",
    "        \n",
    "        else:\n",
    "            print(\"WARNING: unbalanced output\")\n",
    "            \n",
    "            # TODO\n",
    "    else:\n",
    "        total_per = int(count / len(counts.keys()))\n",
    "        remainder = count % len(counts.keys())\n",
    "        if verbose: print(\"Grabbing\", total_per, \"per source\")\n",
    "        \n",
    "        for name in tqdm(counts.keys(), \"Sampling\", disable=(not verbose)):\n",
    "            sample_size = total_per\n",
    "            if remainder > 0: \n",
    "                sample_size += 1\n",
    "                remainder -= 1\n",
    "            source_sample_df = building_df[building_df.source == name].sample(sample_size, random_state=random_seed)\n",
    "            returned_counts[name] = source_sample_df.shape[0]\n",
    "            sample_df = util.stack_dfs(sample_df, source_sample_df)\n",
    "\n",
    "                \n",
    "    return sample_df, returned_counts, rejected\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see notebook 2\n",
    "os_unreliable = ['Addicting Info', 'Breitbart', 'CNS News', 'Intellihub', 'LewRockwell', 'NODISINFO', 'Politicus USA', 'Shareblue', 'The Duran', 'The Gateway Pundit', 'The Political Insider', 'The Washington Examiner', 'TheAntiMedia', 'True Activist', 'Veterans Today']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35ca62dffb2490e97038b061184d2e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Querying sources', max=15, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addicting Info 429 articles\n",
      "Breitbart 1877 articles\n",
      "CNS News 5263 articles\n",
      "Intellihub 334 articles\n",
      "LewRockwell 1278 articles\n",
      "NODISINFO 29 articles\n",
      "NODISINFO rejected\n",
      "Politicus USA 4018 articles\n",
      "Shareblue 2134 articles\n",
      "The Duran 959 articles\n",
      "The Gateway Pundit 5667 articles\n",
      "The Political Insider 2680 articles\n",
      "The Washington Examiner 469 articles\n",
      "TheAntiMedia 666 articles\n",
      "True Activist 370 articles\n",
      "Veterans Today 2624 articles\n",
      "\n",
      "4676 maximum possible balanced sample size\n",
      "Grabbing 321 per source\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "151e95f1cd1e4f0b8920c152b08c0e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Sampling', max=14, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df, counts, rejected = random_balanced_sample(os_unreliable, 4500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Addicting Info': 322,\n",
       " 'Breitbart': 322,\n",
       " 'CNS News': 322,\n",
       " 'Intellihub': 322,\n",
       " 'LewRockwell': 322,\n",
       " 'Politicus USA': 322,\n",
       " 'Shareblue': 321,\n",
       " 'The Duran': 321,\n",
       " 'The Gateway Pundit': 321,\n",
       " 'The Political Insider': 321,\n",
       " 'The Washington Examiner': 321,\n",
       " 'TheAntiMedia': 321,\n",
       " 'True Activist': 321,\n",
       " 'Veterans Today': 321}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
