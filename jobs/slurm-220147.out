2019-11-04 17:31:06,041 - experiment.py - INFO - =====================================================
2019-11-04 17:31:06,041 - experiment.py - INFO - Experiment ../experiments/lstm_reliability_0.json 3 started...
2019-11-04 17:31:06,042 - experiment.py - INFO - =====================================================
2019-11-04 17:31:06,043 - util.py - INFO - CALL::__main__.experiment_model(selection_problem = 'reliability', selection_source = 'os', selection_count = 15000, selection_random_seed = 13, selection_reject_minimum = 500, selection_overwrite = False, embedding_type = 'w2v', embedding_shape = 'sequence', embedding_overwrite = False, test_source = 'mbfc', model_type = 'lstm', model_arch_num = 1, model_layer_sizes = [64, 1], model_maxlen = 500, model_batch_size = 128, model_learning_rate = 0.001, model_epochs = 100, model_num = 3, verbose = False)
2019-11-04 17:31:06,043 - util.py - INFO - CALL::datasets.get_selection_set(problem = 'reliability', source = 'os', count = 15000, random_seed = 13, reject_minimum = 500, overwrite = False, verbose = False)
2019-11-04 17:31:06,063 - util.py - INFO - CALL::datasets.create_selection_set_sources(target_count = 15000, reject_minimum = 500, overwrite = False, verbose = False)
2019-11-04 17:31:06,064 - util.py - INFO - Cached version found.
2019-11-04 17:31:06,065 - datasets.py - INFO - Creating binary selection selection_reliability_os_13...
2019-11-04 17:31:06,066 - util.py - INFO - Cached version found.
2019-11-04 17:31:06,066 - datasets.py - INFO - Loading ../data/cache/selection_reliability_os_13...
Empty DataFrame
Columns: [date, source, name, content, reliable]
Index: []
2019-11-04 17:31:06,157 - util.py - INFO - CALL::datasets.get_embedding_set(df =              date  ... reliable
0      2018-11-12  ...        1
1      2018-04-29  ...        1
2      2018-10-08  ...        1
3      2018-08-29  ...        1
4      2018-11-03  ...        1
...           ...  ...      ...
10651  2018-08-15  ...        0
10652  2018-05-09  ...        0
10653  2018-08-06  ...        0
10654  2018-09-11  ...        0
10655  2018-10-20  ...        0

[10656 rows x 5 columns], embedding_type = 'w2v', output_name = 'selection_reliability_os_13', shaping = 'sequence', overwrite = False)
2019-11-04 17:31:06,157 - datasets.py - INFO - Creating w2v embedding selection_reliability_os_13...
2019-11-04 17:31:06,166 - util.py - INFO - Cached version found.
2019-11-04 17:31:16,904 - util.py - INFO - CALL::datasets.get_test_embedding_set(problem = 'reliability', source = 'os', source_test = 'mbfc', count = 15000, reject_minimum = 500, random_seed = 13, embedding_type = 'w2v', shaping = 'sequence')
2019-11-04 17:31:16,922 - util.py - INFO - CALL::datasets.create_selection_set_sources(target_count = 15000, reject_minimum = 500, overwrite = False, verbose = False)
2019-11-04 17:31:16,938 - util.py - INFO - Cached version found.
2019-11-04 17:31:16,953 - util.py - INFO - CALL::datasets.get_selection_set(problem = 'reliability', source = 'mbfc', count = 15000, random_seed = 13, reject_minimum = 500, overwrite = False, verbose = False)
2019-11-04 17:31:16,970 - util.py - INFO - CALL::datasets.create_selection_set_sources(target_count = 15000, reject_minimum = 500, overwrite = False, verbose = False)
2019-11-04 17:31:16,970 - util.py - INFO - Cached version found.
2019-11-04 17:31:16,978 - datasets.py - INFO - Creating binary selection selection_reliability_mbfc_13...
2019-11-04 17:31:16,978 - util.py - INFO - Cached version found.
2019-11-04 17:31:16,978 - datasets.py - INFO - Loading ../data/cache/selection_reliability_mbfc_13...
Empty DataFrame
Columns: [date, source, name, content, reliable]
Index: []
2019-11-04 17:31:17,103 - util.py - INFO - CALL::datasets.get_embedding_set(df =              date  ... reliable
0      2018-10-19  ...        1
1      2018-11-02  ...        1
2      2018-07-26  ...        1
3      2018-09-06  ...        1
4      2018-07-29  ...        1
...           ...  ...      ...
29995  2018-11-16  ...        0
29996  2018-08-30  ...        0
29997  2018-10-22  ...        0
29998  2018-09-24  ...        0
29999  2018-08-07  ...        0

[30000 rows x 5 columns], embedding_type = 'w2v', output_name = 'selection_reliability_mbfc_13', shaping = 'sequence', overwrite = False)
2019-11-04 17:31:17,103 - datasets.py - INFO - Creating w2v embedding selection_reliability_mbfc_13...
2019-11-04 17:31:17,103 - util.py - INFO - Cached version found.
2019-11-04 17:31:42,245 - util.py - INFO - CALL::lstm.train_test(X = array([[[ 0.45898438,  0.23535156,  0.09765625, ...,  0.24707031,
         -0.33984375,  0.203125  ],
        [-0.05493164,  0.18359375,  0.15039062, ...,  0.08740234,
          0.04223633, -0.00616455],
        [ 0.30664062,  0.11035156,  0.16699219, ...,  0.12890625,
          0.00744629, -0.11328125],
        ...,
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ]],

       [[ 0.25195312, -0.0246582 , -0.15136719, ...,  0.15136719,
         -0.31640625,  0.48632812],
        [-0.05493164,  0.18359375,  0.15039062, ...,  0.08740234,
          0.04223633, -0.00616455],
        [-0.07080078, -0.03735352, -0.00062561, ...,  0.06445312,
         -0.20898438,  0.51953125],
        ...,
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ]],

       [[-0.20410156, -0.09375   ,  0.06787109, ...,  0.30664062,
         -0.29296875,  0.31054688],
        [-0.05493164,  0.18359375,  0.15039062, ...,  0.08740234,
          0.04223633, -0.00616455],
        [-0.20019531,  0.07519531,  0.17773438, ...,  0.03295898,
          0.14355469,  0.01000977],
        ...,
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ]],

       ...,

       [[-0.04321289, -0.01080322,  0.21582031, ...,  0.26367188,
          0.13183594,  0.02648926],
        [ 0.06982422,  0.06591797, -0.14648438, ...,  0.03613281,
          0.19335938, -0.125     ],
        [-0.0255127 ,  0.00775146, -0.0612793 , ..., -0.14160156,
         -0.15136719, -0.23046875],
        ...,
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ]],

       [[ 0.11328125,  0.22265625, -0.22460938, ...,  0.03540039,
          0.03466797, -0.16894531],
        [-0.01708984,  0.02172852,  0.22558594, ..., -0.09130859,
         -0.06982422, -0.02160645],
        [ 0.13867188, -0.09179688,  0.03491211, ..., -0.04174805,
         -0.06079102, -0.09765625],
        ...,
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ]],

       [[-0.17285156,  0.27929688,  0.10693359, ...,  0.12304688,
          0.12988281, -0.18261719],
        [-0.01806641,  0.00854492,  0.06982422, ..., -0.125     ,
         -0.05615234, -0.10839844],
        [ 0.02600098, -0.00189209,  0.18554688, ..., -0.12158203,
          0.22167969, -0.02197266],
        ...,
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ]]], dtype=float32), y = 0        1
1        1
2        1
3        1
4        1
        ..
10651    0
10652    0
10653    0
10654    0
10655    0
Name: reliable, Length: 10656, dtype: int64, arch_num = 1, layer_sizes = [64, 1], maxlen = 500, batch_size = 128, learning_rate = 0.001, epochs = 100, X_test = array([[[-0.17285156,  0.27929688,  0.10693359, ...,  0.12304688,
          0.12988281, -0.18261719],
        [ 0.14257812,  0.07226562,  0.03027344, ..., -0.14160156,
          0.03442383, -0.15234375],
        [ 0.03759766,  0.29101562, -0.11816406, ..., -0.12792969,
          0.24023438, -0.24316406],
        ...,
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ]],

       [[-0.17285156,  0.27929688,  0.10693359, ...,  0.12304688,
          0.12988281, -0.18261719],
        [ 0.00674438, -0.02124023, -0.27734375, ..., -0.13378906,
          0.26757812,  0.37890625],
        [ 0.00704956, -0.07324219,  0.171875  , ...,  0.01123047,
          0.1640625 ,  0.10693359],
        ...,
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ]],

       [[ 0.17871094,  0.09130859, -0.00165558, ...,  0.125     ,
          0.08056641,  0.01672363],
        [ 0.1640625 ,  0.16503906,  0.265625  , ..., -0.03808594,
         -0.01379395, -0.01513672],
        [ 0.0703125 ,  0.08691406,  0.08789062, ..., -0.04760742,
          0.01446533, -0.0625    ],
        ...,
        [-0.00714111,  0.00448608,  0.02062988, ...,  0.01416016,
         -0.06689453, -0.15136719],
        [ 0.5390625 ,  0.24316406,  0.06176758, ..., -0.00601196,
          0.07470703, -0.04931641],
        [-0.11621094,  0.13574219,  0.13671875, ..., -0.20410156,
          0.26171875,  0.1484375 ]],

       ...,

       [[-0.10595703,  0.21386719,  0.11865234, ...,  0.10693359,
          0.02368164, -0.03540039],
        [ 0.03015137,  0.12890625,  0.3046875 , ...,  0.13378906,
          0.140625  ,  0.0390625 ],
        [ 0.31835938,  0.17675781,  0.05859375, ..., -0.09814453,
          0.05249023, -0.00233459],
        ...,
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ]],

       [[-0.22753906, -0.07617188, -0.06787109, ..., -0.109375  ,
          0.26367188,  0.15527344],
        [-0.23632812, -0.02490234, -0.16992188, ..., -0.11425781,
          0.14257812,  0.08984375],
        [-0.17285156,  0.27929688,  0.10693359, ...,  0.12304688,
          0.12988281, -0.18261719],
        ...,
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ]],

       [[ 0.14257812,  0.03735352,  0.02075195, ..., -0.37890625,
          0.05664062,  0.15429688],
        [ 0.26367188,  0.07568359,  0.16699219, ..., -0.29882812,
         -0.08935547, -0.13574219],
        [-0.02636719,  0.06835938, -0.03112793, ..., -0.17089844,
          0.19628906, -0.09960938],
        ...,
        [ 0.109375  ,  0.140625  , -0.03173828, ...,  0.00765991,
          0.12011719, -0.1796875 ],
        [-0.0100708 ,  0.05737305,  0.18359375, ..., -0.12255859,
          0.07617188, -0.234375  ],
        [ 0.04101562,  0.03442383,  0.24609375, ...,  0.3046875 ,
         -0.1953125 , -0.20214844]]], dtype=float32), y_test = 0        0
1        1
2        1
3        0
4        0
        ..
25711    0
25712    0
25713    0
25714    0
25715    1
Name: reliable, Length: 25716, dtype: int64, name = 'selection_reliability_os_13_lstm_1_3_500_128_0.001')
Using TensorFlow backend.
WARNING:tensorflow:From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

2019-11-04 17:31:42,245 - deprecation_wrapper.py - WARNING - From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

2019-11-04 17:31:42,265 - deprecation_wrapper.py - WARNING - From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

2019-11-04 17:31:42,274 - deprecation_wrapper.py - WARNING - From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

2019-11-04 17:31:42,357 - deprecation_wrapper.py - WARNING - From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

WARNING:tensorflow:From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-11-04 17:31:42,363 - deprecation.py - WARNING - From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2974: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2019-11-04 17:31:42,691 - deprecation.py - WARNING - From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2974: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

2019-11-04 17:31:42,742 - deprecation_wrapper.py - WARNING - From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.

2019-11-04 17:31:42,746 - deprecation_wrapper.py - WARNING - From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.

2019-11-04 17:31:46.105386: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-11-04 17:31:46.113048: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2394370000 Hz
2019-11-04 17:31:46.113211: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5556e3e3ee20 executing computations on platform Host. Devices:
2019-11-04 17:31:46.113226: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-11-04 17:31:46.115643: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/cuda91/toolkit/9.1.85/extras/CUPTI/lib64:/cm/local/apps/cuda/libs/current/lib64:/cm/shared/apps/cuda91/toolkit/9.1.85/targets/x86_64-linux/lib:/cm/local/apps/gcc/6.3.0/lib:/cm/local/apps/gcc/6.3.0/lib64:/cm/shared/apps/openmpi/gcc/64/1.10.3/lib64:/cm/shared/apps/slurm/17.02.10/lib64/slurm:/cm/shared/apps/slurm/17.02.10/lib64
2019-11-04 17:31:46.115664: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)
2019-11-04 17:31:46.115695: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node037): /proc/driver/nvidia/version does not exist
2019-11-04 17:31:46.308382: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
masking_1 (Masking)          (None, 500, 300)          0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 64)                93440     
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 65        
=================================================================
Total params: 93,505
Trainable params: 93,505
Non-trainable params: 0
_________________________________________________________________
Train on 8524 samples, validate on 2132 samples
Epoch 1/100
 - 174s - loss: 0.4660 - binary_accuracy: 0.7980 - val_loss: 0.3731 - val_binary_accuracy: 0.8504
Epoch 2/100
 - 171s - loss: 0.3252 - binary_accuracy: 0.8753 - val_loss: 0.2883 - val_binary_accuracy: 0.8968
Epoch 3/100
 - 171s - loss: 0.3106 - binary_accuracy: 0.8820 - val_loss: 0.2971 - val_binary_accuracy: 0.8945
Epoch 4/100
 - 170s - loss: 0.3234 - binary_accuracy: 0.8733 - val_loss: 0.3009 - val_binary_accuracy: 0.9015
Epoch 5/100
 - 172s - loss: 0.3778 - binary_accuracy: 0.8579 - val_loss: 0.2479 - val_binary_accuracy: 0.9170
Epoch 6/100
 - 173s - loss: 0.2677 - binary_accuracy: 0.9020 - val_loss: 0.2339 - val_binary_accuracy: 0.9198
Epoch 7/100
 - 173s - loss: 0.2564 - binary_accuracy: 0.9052 - val_loss: 0.2124 - val_binary_accuracy: 0.9254
Epoch 8/100
 - 173s - loss: 0.2335 - binary_accuracy: 0.9146 - val_loss: 0.2146 - val_binary_accuracy: 0.9273
Epoch 9/100
 - 173s - loss: 0.2327 - binary_accuracy: 0.9113 - val_loss: 0.2036 - val_binary_accuracy: 0.9301
Epoch 10/100
 - 173s - loss: 0.2445 - binary_accuracy: 0.9086 - val_loss: 0.2050 - val_binary_accuracy: 0.9287
Epoch 11/100
 - 168s - loss: 0.2347 - binary_accuracy: 0.9006 - val_loss: 0.1887 - val_binary_accuracy: 0.9221
Epoch 12/100
 - 173s - loss: 0.2113 - binary_accuracy: 0.9106 - val_loss: 0.2017 - val_binary_accuracy: 0.9212
Epoch 13/100
 - 173s - loss: 0.1990 - binary_accuracy: 0.9222 - val_loss: 0.1846 - val_binary_accuracy: 0.9395
Epoch 14/100
 - 173s - loss: 0.2102 - binary_accuracy: 0.9221 - val_loss: 0.1784 - val_binary_accuracy: 0.9428
Epoch 15/100
 - 173s - loss: 0.2023 - binary_accuracy: 0.9202 - val_loss: 0.1513 - val_binary_accuracy: 0.9489
Epoch 16/100
 - 173s - loss: 0.1978 - binary_accuracy: 0.9381 - val_loss: 0.1421 - val_binary_accuracy: 0.9545
Epoch 17/100
 - 173s - loss: 0.1461 - binary_accuracy: 0.9515 - val_loss: 0.1208 - val_binary_accuracy: 0.9587
Epoch 18/100
 - 173s - loss: 0.1308 - binary_accuracy: 0.9546 - val_loss: 0.1006 - val_binary_accuracy: 0.9658
Epoch 19/100
 - 172s - loss: 0.1154 - binary_accuracy: 0.9595 - val_loss: 0.0932 - val_binary_accuracy: 0.9714
Epoch 20/100
 - 174s - loss: 0.1107 - binary_accuracy: 0.9620 - val_loss: 0.0933 - val_binary_accuracy: 0.9705
Epoch 21/100
 - 173s - loss: 0.1076 - binary_accuracy: 0.9632 - val_loss: 0.0927 - val_binary_accuracy: 0.9686
Epoch 22/100
 - 172s - loss: 0.0951 - binary_accuracy: 0.9663 - val_loss: 0.0794 - val_binary_accuracy: 0.9723
Epoch 23/100
 - 172s - loss: 0.0952 - binary_accuracy: 0.9670 - val_loss: 0.0843 - val_binary_accuracy: 0.9723
Epoch 24/100
 - 173s - loss: 0.0967 - binary_accuracy: 0.9682 - val_loss: 0.0871 - val_binary_accuracy: 0.9728
Epoch 25/100
 - 173s - loss: 0.0904 - binary_accuracy: 0.9702 - val_loss: 0.0824 - val_binary_accuracy: 0.9728

  128/25716 [..............................] - ETA: 2:53
  256/25716 [..............................] - ETA: 2:54
  384/25716 [..............................] - ETA: 2:55
  512/25716 [..............................] - ETA: 2:55
  640/25716 [..............................] - ETA: 2:55
  768/25716 [..............................] - ETA: 2:54
  896/25716 [>.............................] - ETA: 2:53
 1024/25716 [>.............................] - ETA: 2:52
 1152/25716 [>.............................] - ETA: 2:51
 1280/25716 [>.............................] - ETA: 2:50
 1408/25716 [>.............................] - ETA: 2:49
 1536/25716 [>.............................] - ETA: 2:48
 1664/25716 [>.............................] - ETA: 2:47
 1792/25716 [=>............................] - ETA: 2:46
 1920/25716 [=>............................] - ETA: 2:46
 2048/25716 [=>............................] - ETA: 2:45
 2176/25716 [=>............................] - ETA: 2:44
 2304/25716 [=>............................] - ETA: 2:43
 2432/25716 [=>............................] - ETA: 2:42
 2560/25716 [=>............................] - ETA: 2:41
 2688/25716 [==>...........................] - ETA: 2:40
 2816/25716 [==>...........................] - ETA: 2:39
 2944/25716 [==>...........................] - ETA: 2:38
 3072/25716 [==>...........................] - ETA: 2:38
 3200/25716 [==>...........................] - ETA: 2:37
 3328/25716 [==>...........................] - ETA: 2:36
 3456/25716 [===>..........................] - ETA: 2:35
 3584/25716 [===>..........................] - ETA: 2:34
 3712/25716 [===>..........................] - ETA: 2:33
 3840/25716 [===>..........................] - ETA: 2:32
 3968/25716 [===>..........................] - ETA: 2:32
 4096/25716 [===>..........................] - ETA: 2:31
 4224/25716 [===>..........................] - ETA: 2:30
 4352/25716 [====>.........................] - ETA: 2:29
 4480/25716 [====>.........................] - ETA: 2:28
 4608/25716 [====>.........................] - ETA: 2:27
 4736/25716 [====>.........................] - ETA: 2:26
 4864/25716 [====>.........................] - ETA: 2:25
 4992/25716 [====>.........................] - ETA: 2:24
 5120/25716 [====>.........................] - ETA: 2:23
 5248/25716 [=====>........................] - ETA: 2:23
 5376/25716 [=====>........................] - ETA: 2:22
 5504/25716 [=====>........................] - ETA: 2:21
 5632/25716 [=====>........................] - ETA: 2:20
 5760/25716 [=====>........................] - ETA: 2:19
 5888/25716 [=====>........................] - ETA: 2:18
 6016/25716 [======>.......................] - ETA: 2:17
 6144/25716 [======>.......................] - ETA: 2:16
 6272/25716 [======>.......................] - ETA: 2:15
 6400/25716 [======>.......................] - ETA: 2:15
 6528/25716 [======>.......................] - ETA: 2:14
 6656/25716 [======>.......................] - ETA: 2:13
 6784/25716 [======>.......................] - ETA: 2:12
 6912/25716 [=======>......................] - ETA: 2:11
 7040/25716 [=======>......................] - ETA: 2:10
 7168/25716 [=======>......................] - ETA: 2:09
 7296/25716 [=======>......................] - ETA: 2:08
 7424/25716 [=======>......................] - ETA: 2:07
 7552/25716 [=======>......................] - ETA: 2:06
 7680/25716 [=======>......................] - ETA: 2:06
 7808/25716 [========>.....................] - ETA: 2:05
 7936/25716 [========>.....................] - ETA: 2:04
 8064/25716 [========>.....................] - ETA: 2:03
 8192/25716 [========>.....................] - ETA: 2:02
 8320/25716 [========>.....................] - ETA: 2:01
 8448/25716 [========>.....................] - ETA: 2:00
 8576/25716 [=========>....................] - ETA: 1:59
 8704/25716 [=========>....................] - ETA: 1:59
 8832/25716 [=========>....................] - ETA: 1:58
 8960/25716 [=========>....................] - ETA: 1:57
 9088/25716 [=========>....................] - ETA: 1:56
 9216/25716 [=========>....................] - ETA: 1:55
 9344/25716 [=========>....................] - ETA: 1:54
 9472/25716 [==========>...................] - ETA: 1:53
 9600/25716 [==========>...................] - ETA: 1:52
 9728/25716 [==========>...................] - ETA: 1:52
 9856/25716 [==========>...................] - ETA: 1:51
 9984/25716 [==========>...................] - ETA: 1:50
10112/25716 [==========>...................] - ETA: 1:49
10240/25716 [==========>...................] - ETA: 1:48
10368/25716 [===========>..................] - ETA: 1:47
10496/25716 [===========>..................] - ETA: 1:46
10624/25716 [===========>..................] - ETA: 1:45
10752/25716 [===========>..................] - ETA: 1:44
10880/25716 [===========>..................] - ETA: 1:44
11008/25716 [===========>..................] - ETA: 1:43
11136/25716 [===========>..................] - ETA: 1:42
11264/25716 [============>.................] - ETA: 1:41
11392/25716 [============>.................] - ETA: 1:40
11520/25716 [============>.................] - ETA: 1:39
11648/25716 [============>.................] - ETA: 1:38
11776/25716 [============>.................] - ETA: 1:37
11904/25716 [============>.................] - ETA: 1:37
12032/25716 [=============>................] - ETA: 1:36
12160/25716 [=============>................] - ETA: 1:35
12288/25716 [=============>................] - ETA: 1:34
12416/25716 [=============>................] - ETA: 1:33
12544/25716 [=============>................] - ETA: 1:32
12672/25716 [=============>................] - ETA: 1:31
12800/25716 [=============>................] - ETA: 1:30
12928/25716 [==============>...............] - ETA: 1:29
13056/25716 [==============>...............] - ETA: 1:28
13184/25716 [==============>...............] - ETA: 1:28
13312/25716 [==============>...............] - ETA: 1:27
13440/25716 [==============>...............] - ETA: 1:26
13568/25716 [==============>...............] - ETA: 1:25
13696/25716 [==============>...............] - ETA: 1:24
13824/25716 [===============>..............] - ETA: 1:23
13952/25716 [===============>..............] - ETA: 1:22
14080/25716 [===============>..............] - ETA: 1:21
14208/25716 [===============>..............] - ETA: 1:20
14336/25716 [===============>..............] - ETA: 1:19
14464/25716 [===============>..............] - ETA: 1:19
14592/25716 [================>.............] - ETA: 1:18
14720/25716 [================>.............] - ETA: 1:17
14848/25716 [================>.............] - ETA: 1:16
14976/25716 [================>.............] - ETA: 1:15
15104/25716 [================>.............] - ETA: 1:14
15232/25716 [================>.............] - ETA: 1:13
15360/25716 [================>.............] - ETA: 1:12
15488/25716 [=================>............] - ETA: 1:11
15616/25716 [=================>............] - ETA: 1:10
15744/25716 [=================>............] - ETA: 1:10
15872/25716 [=================>............] - ETA: 1:09
16000/25716 [=================>............] - ETA: 1:08
16128/25716 [=================>............] - ETA: 1:07
16256/25716 [=================>............] - ETA: 1:06
16384/25716 [==================>...........] - ETA: 1:05
16512/25716 [==================>...........] - ETA: 1:04
16640/25716 [==================>...........] - ETA: 1:03
16768/25716 [==================>...........] - ETA: 1:02
16896/25716 [==================>...........] - ETA: 1:01
17024/25716 [==================>...........] - ETA: 1:01
17152/25716 [===================>..........] - ETA: 1:00
17280/25716 [===================>..........] - ETA: 59s 
17408/25716 [===================>..........] - ETA: 58s
17536/25716 [===================>..........] - ETA: 57s
17664/25716 [===================>..........] - ETA: 56s
17792/25716 [===================>..........] - ETA: 55s
17920/25716 [===================>..........] - ETA: 54s
18048/25716 [====================>.........] - ETA: 53s
18176/25716 [====================>.........] - ETA: 52s
18304/25716 [====================>.........] - ETA: 52s
18432/25716 [====================>.........] - ETA: 51s
18560/25716 [====================>.........] - ETA: 50s
18688/25716 [====================>.........] - ETA: 49s
18816/25716 [====================>.........] - ETA: 48s
18944/25716 [=====================>........] - ETA: 47s
19072/25716 [=====================>........] - ETA: 46s
19200/25716 [=====================>........] - ETA: 45s
19328/25716 [=====================>........] - ETA: 44s
19456/25716 [=====================>........] - ETA: 43s
19584/25716 [=====================>........] - ETA: 43s
19712/25716 [=====================>........] - ETA: 42s
19840/25716 [======================>.......] - ETA: 41s
19968/25716 [======================>.......] - ETA: 40s
20096/25716 [======================>.......] - ETA: 39s
20224/25716 [======================>.......] - ETA: 38s
20352/25716 [======================>.......] - ETA: 37s
20480/25716 [======================>.......] - ETA: 36s
20608/25716 [=======================>......] - ETA: 35s
20736/25716 [=======================>......] - ETA: 34s
20864/25716 [=======================>......] - ETA: 34s
20992/25716 [=======================>......] - ETA: 33s
21120/25716 [=======================>......] - ETA: 32s
21248/25716 [=======================>......] - ETA: 31s
21376/25716 [=======================>......] - ETA: 30s
21504/25716 [========================>.....] - ETA: 29s
21632/25716 [========================>.....] - ETA: 28s
21760/25716 [========================>.....] - ETA: 27s
21888/25716 [========================>.....] - ETA: 26s
22016/25716 [========================>.....] - ETA: 25s
22144/25716 [========================>.....] - ETA: 25s
22272/25716 [========================>.....] - ETA: 24s
22400/25716 [=========================>....] - ETA: 23s
22528/25716 [=========================>....] - ETA: 22s
22656/25716 [=========================>....] - ETA: 21s
22784/25716 [=========================>....] - ETA: 20s
22912/25716 [=========================>....] - ETA: 19s
23040/25716 [=========================>....] - ETA: 18s
23168/25716 [==========================>...] - ETA: 17s
23296/25716 [==========================>...] - ETA: 16s
23424/25716 [==========================>...] - ETA: 16s
23552/25716 [==========================>...] - ETA: 15s
23680/25716 [==========================>...] - ETA: 14s
23808/25716 [==========================>...] - ETA: 13s
23936/25716 [==========================>...] - ETA: 12s
24064/25716 [===========================>..] - ETA: 11s
24192/25716 [===========================>..] - ETA: 10s
24320/25716 [===========================>..] - ETA: 9s 
24448/25716 [===========================>..] - ETA: 8s
24576/25716 [===========================>..] - ETA: 8s
24704/25716 [===========================>..] - ETA: 7s
24832/25716 [===========================>..] - ETA: 6s
24960/25716 [============================>.] - ETA: 5s
25088/25716 [============================>.] - ETA: 4s
25216/25716 [============================>.] - ETA: 3s
25344/25716 [============================>.] - ETA: 2s
25472/25716 [============================>.] - ETA: 1s
25600/25716 [============================>.] - ETA: 0s
25716/25716 [==============================] - 180s 7ms/step
2019-11-04 18:46:37,508 - lstm.py - INFO - Test loss / test accuracy: 1.790739 / 0.521699
