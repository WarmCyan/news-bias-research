2019-11-04 17:30:25,594 - experiment.py - INFO - =====================================================
2019-11-04 17:30:25,594 - experiment.py - INFO - Experiment ../experiments/lstm_reliability_0.json 2 started...
2019-11-04 17:30:25,595 - experiment.py - INFO - =====================================================
2019-11-04 17:30:25,596 - util.py - INFO - CALL::__main__.experiment_model(selection_problem = 'reliability', selection_source = 'os', selection_count = 15000, selection_random_seed = 13, selection_reject_minimum = 500, selection_overwrite = False, embedding_type = 'w2v', embedding_shape = 'sequence', embedding_overwrite = False, test_source = 'mbfc', model_type = 'lstm', model_arch_num = 1, model_layer_sizes = [32, 1], model_maxlen = 500, model_batch_size = 128, model_learning_rate = 0.001, model_epochs = 100, model_num = 2, verbose = False)
2019-11-04 17:30:25,596 - util.py - INFO - CALL::datasets.get_selection_set(problem = 'reliability', source = 'os', count = 15000, random_seed = 13, reject_minimum = 500, overwrite = False, verbose = False)
2019-11-04 17:30:25,667 - util.py - INFO - CALL::datasets.create_selection_set_sources(target_count = 15000, reject_minimum = 500, overwrite = False, verbose = False)
2019-11-04 17:30:25,743 - util.py - INFO - Cached version found.
2019-11-04 17:30:25,758 - datasets.py - INFO - Creating binary selection selection_reliability_os_13...
2019-11-04 17:30:25,767 - util.py - INFO - Cached version found.
2019-11-04 17:30:25,767 - datasets.py - INFO - Loading ../data/cache/selection_reliability_os_13...
Empty DataFrame
Columns: [date, source, name, content, reliable]
Index: []
2019-11-04 17:30:25,972 - util.py - INFO - CALL::datasets.get_embedding_set(df =              date  ... reliable
0      2018-11-12  ...        1
1      2018-04-29  ...        1
2      2018-10-08  ...        1
3      2018-08-29  ...        1
4      2018-11-03  ...        1
...           ...  ...      ...
10651  2018-08-15  ...        0
10652  2018-05-09  ...        0
10653  2018-08-06  ...        0
10654  2018-09-11  ...        0
10655  2018-10-20  ...        0

[10656 rows x 5 columns], embedding_type = 'w2v', output_name = 'selection_reliability_os_13', shaping = 'sequence', overwrite = False)
2019-11-04 17:30:25,972 - datasets.py - INFO - Creating w2v embedding selection_reliability_os_13...
2019-11-04 17:30:25,972 - util.py - INFO - Cached version found.
2019-11-04 17:30:37,937 - util.py - INFO - CALL::datasets.get_test_embedding_set(problem = 'reliability', source = 'os', source_test = 'mbfc', count = 15000, reject_minimum = 500, random_seed = 13, embedding_type = 'w2v', shaping = 'sequence')
2019-11-04 17:30:37,938 - util.py - INFO - CALL::datasets.create_selection_set_sources(target_count = 15000, reject_minimum = 500, overwrite = False, verbose = False)
2019-11-04 17:30:37,938 - util.py - INFO - Cached version found.
2019-11-04 17:30:37,939 - util.py - INFO - CALL::datasets.get_selection_set(problem = 'reliability', source = 'mbfc', count = 15000, random_seed = 13, reject_minimum = 500, overwrite = False, verbose = False)
2019-11-04 17:30:37,948 - util.py - INFO - CALL::datasets.create_selection_set_sources(target_count = 15000, reject_minimum = 500, overwrite = False, verbose = False)
2019-11-04 17:30:37,948 - util.py - INFO - Cached version found.
2019-11-04 17:30:37,951 - datasets.py - INFO - Creating binary selection selection_reliability_mbfc_13...
2019-11-04 17:30:37,951 - util.py - INFO - Cached version found.
2019-11-04 17:30:37,951 - datasets.py - INFO - Loading ../data/cache/selection_reliability_mbfc_13...
Empty DataFrame
Columns: [date, source, name, content, reliable]
Index: []
2019-11-04 17:30:38,075 - util.py - INFO - CALL::datasets.get_embedding_set(df =              date  ... reliable
0      2018-10-19  ...        1
1      2018-11-02  ...        1
2      2018-07-26  ...        1
3      2018-09-06  ...        1
4      2018-07-29  ...        1
...           ...  ...      ...
29995  2018-11-16  ...        0
29996  2018-08-30  ...        0
29997  2018-10-22  ...        0
29998  2018-09-24  ...        0
29999  2018-08-07  ...        0

[30000 rows x 5 columns], embedding_type = 'w2v', output_name = 'selection_reliability_mbfc_13', shaping = 'sequence', overwrite = False)
2019-11-04 17:30:38,075 - datasets.py - INFO - Creating w2v embedding selection_reliability_mbfc_13...
2019-11-04 17:30:38,076 - util.py - INFO - Cached version found.
2019-11-04 17:31:31,189 - util.py - INFO - CALL::lstm.train_test(X = array([[[ 0.45898438,  0.23535156,  0.09765625, ...,  0.24707031,
         -0.33984375,  0.203125  ],
        [-0.05493164,  0.18359375,  0.15039062, ...,  0.08740234,
          0.04223633, -0.00616455],
        [ 0.30664062,  0.11035156,  0.16699219, ...,  0.12890625,
          0.00744629, -0.11328125],
        ...,
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ]],

       [[ 0.25195312, -0.0246582 , -0.15136719, ...,  0.15136719,
         -0.31640625,  0.48632812],
        [-0.05493164,  0.18359375,  0.15039062, ...,  0.08740234,
          0.04223633, -0.00616455],
        [-0.07080078, -0.03735352, -0.00062561, ...,  0.06445312,
         -0.20898438,  0.51953125],
        ...,
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ]],

       [[-0.20410156, -0.09375   ,  0.06787109, ...,  0.30664062,
         -0.29296875,  0.31054688],
        [-0.05493164,  0.18359375,  0.15039062, ...,  0.08740234,
          0.04223633, -0.00616455],
        [-0.20019531,  0.07519531,  0.17773438, ...,  0.03295898,
          0.14355469,  0.01000977],
        ...,
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ]],

       ...,

       [[-0.04321289, -0.01080322,  0.21582031, ...,  0.26367188,
          0.13183594,  0.02648926],
        [ 0.06982422,  0.06591797, -0.14648438, ...,  0.03613281,
          0.19335938, -0.125     ],
        [-0.0255127 ,  0.00775146, -0.0612793 , ..., -0.14160156,
         -0.15136719, -0.23046875],
        ...,
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ]],

       [[ 0.11328125,  0.22265625, -0.22460938, ...,  0.03540039,
          0.03466797, -0.16894531],
        [-0.01708984,  0.02172852,  0.22558594, ..., -0.09130859,
         -0.06982422, -0.02160645],
        [ 0.13867188, -0.09179688,  0.03491211, ..., -0.04174805,
         -0.06079102, -0.09765625],
        ...,
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ]],

       [[-0.17285156,  0.27929688,  0.10693359, ...,  0.12304688,
          0.12988281, -0.18261719],
        [-0.01806641,  0.00854492,  0.06982422, ..., -0.125     ,
         -0.05615234, -0.10839844],
        [ 0.02600098, -0.00189209,  0.18554688, ..., -0.12158203,
          0.22167969, -0.02197266],
        ...,
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ]]], dtype=float32), y = 0        1
1        1
2        1
3        1
4        1
        ..
10651    0
10652    0
10653    0
10654    0
10655    0
Name: reliable, Length: 10656, dtype: int64, arch_num = 1, layer_sizes = [32, 1], maxlen = 500, batch_size = 128, learning_rate = 0.001, epochs = 100, X_test = array([[[-0.17285156,  0.27929688,  0.10693359, ...,  0.12304688,
          0.12988281, -0.18261719],
        [ 0.14257812,  0.07226562,  0.03027344, ..., -0.14160156,
          0.03442383, -0.15234375],
        [ 0.03759766,  0.29101562, -0.11816406, ..., -0.12792969,
          0.24023438, -0.24316406],
        ...,
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ]],

       [[-0.17285156,  0.27929688,  0.10693359, ...,  0.12304688,
          0.12988281, -0.18261719],
        [ 0.00674438, -0.02124023, -0.27734375, ..., -0.13378906,
          0.26757812,  0.37890625],
        [ 0.00704956, -0.07324219,  0.171875  , ...,  0.01123047,
          0.1640625 ,  0.10693359],
        ...,
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ]],

       [[ 0.17871094,  0.09130859, -0.00165558, ...,  0.125     ,
          0.08056641,  0.01672363],
        [ 0.1640625 ,  0.16503906,  0.265625  , ..., -0.03808594,
         -0.01379395, -0.01513672],
        [ 0.0703125 ,  0.08691406,  0.08789062, ..., -0.04760742,
          0.01446533, -0.0625    ],
        ...,
        [-0.00714111,  0.00448608,  0.02062988, ...,  0.01416016,
         -0.06689453, -0.15136719],
        [ 0.5390625 ,  0.24316406,  0.06176758, ..., -0.00601196,
          0.07470703, -0.04931641],
        [-0.11621094,  0.13574219,  0.13671875, ..., -0.20410156,
          0.26171875,  0.1484375 ]],

       ...,

       [[-0.10595703,  0.21386719,  0.11865234, ...,  0.10693359,
          0.02368164, -0.03540039],
        [ 0.03015137,  0.12890625,  0.3046875 , ...,  0.13378906,
          0.140625  ,  0.0390625 ],
        [ 0.31835938,  0.17675781,  0.05859375, ..., -0.09814453,
          0.05249023, -0.00233459],
        ...,
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ]],

       [[-0.22753906, -0.07617188, -0.06787109, ..., -0.109375  ,
          0.26367188,  0.15527344],
        [-0.23632812, -0.02490234, -0.16992188, ..., -0.11425781,
          0.14257812,  0.08984375],
        [-0.17285156,  0.27929688,  0.10693359, ...,  0.12304688,
          0.12988281, -0.18261719],
        ...,
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ],
        [ 0.        ,  0.        ,  0.        , ...,  0.        ,
          0.        ,  0.        ]],

       [[ 0.14257812,  0.03735352,  0.02075195, ..., -0.37890625,
          0.05664062,  0.15429688],
        [ 0.26367188,  0.07568359,  0.16699219, ..., -0.29882812,
         -0.08935547, -0.13574219],
        [-0.02636719,  0.06835938, -0.03112793, ..., -0.17089844,
          0.19628906, -0.09960938],
        ...,
        [ 0.109375  ,  0.140625  , -0.03173828, ...,  0.00765991,
          0.12011719, -0.1796875 ],
        [-0.0100708 ,  0.05737305,  0.18359375, ..., -0.12255859,
          0.07617188, -0.234375  ],
        [ 0.04101562,  0.03442383,  0.24609375, ...,  0.3046875 ,
         -0.1953125 , -0.20214844]]], dtype=float32), y_test = 0        0
1        1
2        1
3        0
4        0
        ..
25711    0
25712    0
25713    0
25714    0
25715    1
Name: reliable, Length: 25716, dtype: int64, name = 'selection_reliability_os_13_lstm_1_2_500_128_0.001')
Using TensorFlow backend.
WARNING:tensorflow:From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

2019-11-04 17:31:31,190 - deprecation_wrapper.py - WARNING - From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

2019-11-04 17:31:31,212 - deprecation_wrapper.py - WARNING - From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

2019-11-04 17:31:31,221 - deprecation_wrapper.py - WARNING - From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

2019-11-04 17:31:31,289 - deprecation_wrapper.py - WARNING - From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

WARNING:tensorflow:From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-11-04 17:31:31,295 - deprecation.py - WARNING - From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2974: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2019-11-04 17:31:31,613 - deprecation.py - WARNING - From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2974: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

2019-11-04 17:31:31,661 - deprecation_wrapper.py - WARNING - From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.

2019-11-04 17:31:31,664 - deprecation_wrapper.py - WARNING - From /home/tntech.edu/namartinda42/.conda/envs/tensorflow-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.

2019-11-04 17:31:36.977019: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-11-04 17:31:36.985158: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2394360000 Hz
2019-11-04 17:31:36.985313: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555a00ab66a0 executing computations on platform Host. Devices:
2019-11-04 17:31:36.985327: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-11-04 17:31:36.987646: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/cuda91/toolkit/9.1.85/extras/CUPTI/lib64:/cm/local/apps/cuda/libs/current/lib64:/cm/shared/apps/cuda91/toolkit/9.1.85/targets/x86_64-linux/lib:/cm/local/apps/gcc/6.3.0/lib:/cm/local/apps/gcc/6.3.0/lib64:/cm/shared/apps/openmpi/gcc/64/1.10.3/lib64:/cm/shared/apps/slurm/17.02.10/lib64/slurm:/cm/shared/apps/slurm/17.02.10/lib64
2019-11-04 17:31:36.987668: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)
2019-11-04 17:31:36.987690: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node035): /proc/driver/nvidia/version does not exist
2019-11-04 17:31:37.179451: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
masking_1 (Masking)          (None, 500, 300)          0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 32)                42624     
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 33        
=================================================================
Total params: 42,657
Trainable params: 42,657
Non-trainable params: 0
_________________________________________________________________
Train on 8524 samples, validate on 2132 samples
Epoch 1/100
 - 128s - loss: 0.4721 - binary_accuracy: 0.7953 - val_loss: 0.3686 - val_binary_accuracy: 0.8823
Epoch 2/100
 - 125s - loss: 0.3571 - binary_accuracy: 0.8624 - val_loss: 0.3077 - val_binary_accuracy: 0.8917
Epoch 3/100
 - 125s - loss: 0.4210 - binary_accuracy: 0.8238 - val_loss: 0.3374 - val_binary_accuracy: 0.8804
Epoch 4/100
 - 125s - loss: 0.3296 - binary_accuracy: 0.8708 - val_loss: 0.3185 - val_binary_accuracy: 0.8780
Epoch 5/100
 - 124s - loss: 0.3155 - binary_accuracy: 0.8782 - val_loss: 0.3101 - val_binary_accuracy: 0.8870

  128/25716 [..............................] - ETA: 2:05
  256/25716 [..............................] - ETA: 2:10
  384/25716 [..............................] - ETA: 2:09
  512/25716 [..............................] - ETA: 2:10
  640/25716 [..............................] - ETA: 2:09
  768/25716 [..............................] - ETA: 2:09
  896/25716 [>.............................] - ETA: 2:08
 1024/25716 [>.............................] - ETA: 2:08
 1152/25716 [>.............................] - ETA: 2:07
 1280/25716 [>.............................] - ETA: 2:06
 1408/25716 [>.............................] - ETA: 2:05
 1536/25716 [>.............................] - ETA: 2:05
 1664/25716 [>.............................] - ETA: 2:04
 1792/25716 [=>............................] - ETA: 2:03
 1920/25716 [=>............................] - ETA: 2:02
 2048/25716 [=>............................] - ETA: 2:01
 2176/25716 [=>............................] - ETA: 2:01
 2304/25716 [=>............................] - ETA: 2:00
 2432/25716 [=>............................] - ETA: 1:59
 2560/25716 [=>............................] - ETA: 1:59
 2688/25716 [==>...........................] - ETA: 1:58
 2816/25716 [==>...........................] - ETA: 1:58
 2944/25716 [==>...........................] - ETA: 1:57
 3072/25716 [==>...........................] - ETA: 1:56
 3200/25716 [==>...........................] - ETA: 1:56
 3328/25716 [==>...........................] - ETA: 1:55
 3456/25716 [===>..........................] - ETA: 1:55
 3584/25716 [===>..........................] - ETA: 1:54
 3712/25716 [===>..........................] - ETA: 1:53
 3840/25716 [===>..........................] - ETA: 1:53
 3968/25716 [===>..........................] - ETA: 1:52
 4096/25716 [===>..........................] - ETA: 1:51
 4224/25716 [===>..........................] - ETA: 1:51
 4352/25716 [====>.........................] - ETA: 1:50
 4480/25716 [====>.........................] - ETA: 1:49
 4608/25716 [====>.........................] - ETA: 1:49
 4736/25716 [====>.........................] - ETA: 1:48
 4864/25716 [====>.........................] - ETA: 1:47
 4992/25716 [====>.........................] - ETA: 1:47
 5120/25716 [====>.........................] - ETA: 1:46
 5248/25716 [=====>........................] - ETA: 1:45
 5376/25716 [=====>........................] - ETA: 1:44
 5504/25716 [=====>........................] - ETA: 1:44
 5632/25716 [=====>........................] - ETA: 1:43
 5760/25716 [=====>........................] - ETA: 1:42
 5888/25716 [=====>........................] - ETA: 1:42
 6016/25716 [======>.......................] - ETA: 1:41
 6144/25716 [======>.......................] - ETA: 1:40
 6272/25716 [======>.......................] - ETA: 1:40
 6400/25716 [======>.......................] - ETA: 1:39
 6528/25716 [======>.......................] - ETA: 1:38
 6656/25716 [======>.......................] - ETA: 1:38
 6784/25716 [======>.......................] - ETA: 1:37
 6912/25716 [=======>......................] - ETA: 1:37
 7040/25716 [=======>......................] - ETA: 1:36
 7168/25716 [=======>......................] - ETA: 1:35
 7296/25716 [=======>......................] - ETA: 1:35
 7424/25716 [=======>......................] - ETA: 1:34
 7552/25716 [=======>......................] - ETA: 1:33
 7680/25716 [=======>......................] - ETA: 1:33
 7808/25716 [========>.....................] - ETA: 1:32
 7936/25716 [========>.....................] - ETA: 1:31
 8064/25716 [========>.....................] - ETA: 1:31
 8192/25716 [========>.....................] - ETA: 1:30
 8320/25716 [========>.....................] - ETA: 1:29
 8448/25716 [========>.....................] - ETA: 1:29
 8576/25716 [=========>....................] - ETA: 1:28
 8704/25716 [=========>....................] - ETA: 1:27
 8832/25716 [=========>....................] - ETA: 1:27
 8960/25716 [=========>....................] - ETA: 1:26
 9088/25716 [=========>....................] - ETA: 1:25
 9216/25716 [=========>....................] - ETA: 1:25
 9344/25716 [=========>....................] - ETA: 1:24
 9472/25716 [==========>...................] - ETA: 1:23
 9600/25716 [==========>...................] - ETA: 1:23
 9728/25716 [==========>...................] - ETA: 1:22
 9856/25716 [==========>...................] - ETA: 1:21
 9984/25716 [==========>...................] - ETA: 1:21
10112/25716 [==========>...................] - ETA: 1:20
10240/25716 [==========>...................] - ETA: 1:19
10368/25716 [===========>..................] - ETA: 1:19
10496/25716 [===========>..................] - ETA: 1:18
10624/25716 [===========>..................] - ETA: 1:18
10752/25716 [===========>..................] - ETA: 1:17
10880/25716 [===========>..................] - ETA: 1:16
11008/25716 [===========>..................] - ETA: 1:16
11136/25716 [===========>..................] - ETA: 1:15
11264/25716 [============>.................] - ETA: 1:14
11392/25716 [============>.................] - ETA: 1:13
11520/25716 [============>.................] - ETA: 1:13
11648/25716 [============>.................] - ETA: 1:12
11776/25716 [============>.................] - ETA: 1:11
11904/25716 [============>.................] - ETA: 1:11
12032/25716 [=============>................] - ETA: 1:10
12160/25716 [=============>................] - ETA: 1:09
12288/25716 [=============>................] - ETA: 1:09
12416/25716 [=============>................] - ETA: 1:08
12544/25716 [=============>................] - ETA: 1:07
12672/25716 [=============>................] - ETA: 1:07
12800/25716 [=============>................] - ETA: 1:06
12928/25716 [==============>...............] - ETA: 1:06
13056/25716 [==============>...............] - ETA: 1:05
13184/25716 [==============>...............] - ETA: 1:04
13312/25716 [==============>...............] - ETA: 1:04
13440/25716 [==============>...............] - ETA: 1:03
13568/25716 [==============>...............] - ETA: 1:02
13696/25716 [==============>...............] - ETA: 1:02
13824/25716 [===============>..............] - ETA: 1:01
13952/25716 [===============>..............] - ETA: 1:00
14080/25716 [===============>..............] - ETA: 1:00
14208/25716 [===============>..............] - ETA: 59s 
14336/25716 [===============>..............] - ETA: 58s
14464/25716 [===============>..............] - ETA: 58s
14592/25716 [================>.............] - ETA: 57s
14720/25716 [================>.............] - ETA: 56s
14848/25716 [================>.............] - ETA: 56s
14976/25716 [================>.............] - ETA: 55s
15104/25716 [================>.............] - ETA: 54s
15232/25716 [================>.............] - ETA: 54s
15360/25716 [================>.............] - ETA: 53s
15488/25716 [=================>............] - ETA: 52s
15616/25716 [=================>............] - ETA: 52s
15744/25716 [=================>............] - ETA: 51s
15872/25716 [=================>............] - ETA: 50s
16000/25716 [=================>............] - ETA: 50s
16128/25716 [=================>............] - ETA: 49s
16256/25716 [=================>............] - ETA: 48s
16384/25716 [==================>...........] - ETA: 48s
16512/25716 [==================>...........] - ETA: 47s
16640/25716 [==================>...........] - ETA: 46s
16768/25716 [==================>...........] - ETA: 46s
16896/25716 [==================>...........] - ETA: 45s
17024/25716 [==================>...........] - ETA: 44s
17152/25716 [===================>..........] - ETA: 44s
17280/25716 [===================>..........] - ETA: 43s
17408/25716 [===================>..........] - ETA: 42s
17536/25716 [===================>..........] - ETA: 42s
17664/25716 [===================>..........] - ETA: 41s
17792/25716 [===================>..........] - ETA: 40s
17920/25716 [===================>..........] - ETA: 40s
18048/25716 [====================>.........] - ETA: 39s
18176/25716 [====================>.........] - ETA: 38s
18304/25716 [====================>.........] - ETA: 38s
18432/25716 [====================>.........] - ETA: 37s
18560/25716 [====================>.........] - ETA: 36s
18688/25716 [====================>.........] - ETA: 36s
18816/25716 [====================>.........] - ETA: 35s
18944/25716 [=====================>........] - ETA: 34s
19072/25716 [=====================>........] - ETA: 34s
19200/25716 [=====================>........] - ETA: 33s
19328/25716 [=====================>........] - ETA: 33s
19456/25716 [=====================>........] - ETA: 32s
19584/25716 [=====================>........] - ETA: 31s
19712/25716 [=====================>........] - ETA: 31s
19840/25716 [======================>.......] - ETA: 30s
19968/25716 [======================>.......] - ETA: 29s
20096/25716 [======================>.......] - ETA: 29s
20224/25716 [======================>.......] - ETA: 28s
20352/25716 [======================>.......] - ETA: 27s
20480/25716 [======================>.......] - ETA: 27s
20608/25716 [=======================>......] - ETA: 26s
20736/25716 [=======================>......] - ETA: 25s
20864/25716 [=======================>......] - ETA: 25s
20992/25716 [=======================>......] - ETA: 24s
21120/25716 [=======================>......] - ETA: 23s
21248/25716 [=======================>......] - ETA: 23s
21376/25716 [=======================>......] - ETA: 22s
21504/25716 [========================>.....] - ETA: 21s
21632/25716 [========================>.....] - ETA: 21s
21760/25716 [========================>.....] - ETA: 20s
21888/25716 [========================>.....] - ETA: 19s
22016/25716 [========================>.....] - ETA: 19s
22144/25716 [========================>.....] - ETA: 18s
22272/25716 [========================>.....] - ETA: 17s
22400/25716 [=========================>....] - ETA: 17s
22528/25716 [=========================>....] - ETA: 16s
22656/25716 [=========================>....] - ETA: 15s
22784/25716 [=========================>....] - ETA: 15s
22912/25716 [=========================>....] - ETA: 14s
23040/25716 [=========================>....] - ETA: 13s
23168/25716 [==========================>...] - ETA: 13s
23296/25716 [==========================>...] - ETA: 12s
23424/25716 [==========================>...] - ETA: 11s
23552/25716 [==========================>...] - ETA: 11s
23680/25716 [==========================>...] - ETA: 10s
23808/25716 [==========================>...] - ETA: 9s 
23936/25716 [==========================>...] - ETA: 9s
24064/25716 [===========================>..] - ETA: 8s
24192/25716 [===========================>..] - ETA: 7s
24320/25716 [===========================>..] - ETA: 7s
24448/25716 [===========================>..] - ETA: 6s
24576/25716 [===========================>..] - ETA: 5s
24704/25716 [===========================>..] - ETA: 5s
24832/25716 [===========================>..] - ETA: 4s
24960/25716 [============================>.] - ETA: 3s
25088/25716 [============================>.] - ETA: 3s
25216/25716 [============================>.] - ETA: 2s
25344/25716 [============================>.] - ETA: 1s
25472/25716 [============================>.] - ETA: 1s
25600/25716 [============================>.] - ETA: 0s
25716/25716 [==============================] - 133s 5ms/step
2019-11-04 17:44:16,756 - lstm.py - INFO - Test loss / test accuracy: 1.188426 / 0.507155
